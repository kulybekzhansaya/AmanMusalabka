{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1L08NR-m0OE"
   },
   "source": [
    "# Сөз векторларымен операциялар (Word Embedding Operations)\n",
    "\n",
    "Осы аптаның тәжірибелік жұмысына қош келдіңіздер!\n",
    "\n",
    "Сөз енгізулері (эмбеддингтері) үйрету өте көп есептеу қуатын талап ететіндіктен, көпшілік ML тәжірибешілері алдын ала үйретілген эмбеддингтер жиынын жүктейді.\n",
    "\n",
    "**Осы тәжірибелік жұмыстан кейін сіз:**\n",
    "\n",
    "- Алдын ала үйретілген сөз векторларын жүктей аласыз және косинус ұқсастығын пайдаланып ұқсастықты өлшей аласыз\n",
    "- Ер – Әйел аналогиясы сияқты сөз аналогиясы мәселелерін шешу үшін сөз енгізулерін қолдана аласыз: Мысалы, Man - Woman, King - ____.\n",
    "- Жыныстық бейсімділікті азайту үшін сөз енгізулерін өзгерте аласыз\n",
    "\n",
    "Бастайық! Қажетті пакеттерді жүктеу үшін төмендегі ұяшықты іске қосыңыз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cUNd4pPlm0OG"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 70, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: Произошел сбой в программе инициализации библиотеки динамической компоновки (DLL).\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:70\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _pywrap_tensorflow_internal: Произошел сбой в программе инициализации библиотеки динамической компоновки (DLL).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mw2v_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\Downloads\\w2v_utils.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, Dense, Reshape, concatenate, Embedding\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m skipgrams\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:85\u001b[0m\n\u001b[0;32m     83\u001b[0m     sys\u001b[38;5;241m.\u001b[39msetdlopenflags(_default_dlopen_flags)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     86\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;241m.\u001b[39mformat_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     87\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     88\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     89\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     90\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you need help, create an issue \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     91\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     92\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand include the entire stack trace above this error message.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 70, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: Произошел сбой в программе инициализации библиотеки динамической компоновки (DLL).\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from w2v_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow==2.10 (from versions: 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.1, 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0)\n",
      "ERROR: No matching distribution found for tensorflow==2.10\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.10 numpy scipy h5py keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUQyO3Zcm0OH"
   },
   "source": [
    "Келесі қадамда, сөз векторларын жүктейік. Бұл тапсырма үшін біз сөздерді көрсету мақсатында 50 өлшемді GloVe векторларын қолданамыз. `word_to_vec_map` жүктеу үшін келесі ұяшықты іске қосыңыз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "hqlDJ0O0m0OH",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "words, word_to_vec_map = read_glove_vecs('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lrq_rsnEm0OH"
   },
   "source": [
    "Сіз жүктегеніңіз:\n",
    "- `words`: сөздік құрамындағы сөздер жиынтығы.\n",
    "- `word_to_vec_map`: сөздерді олардың GloVe векторлық бейнесіне сәйкестендіретін сөздік.\n",
    "\n",
    "Бірлік векторлар сөздердің ұқсастығын жақсы көрсетпейтінін көрдіңіз. GloVe векторлары жеке сөздердің мағынасы туралы әлдеқайда пайдалы ақпарат береді. Енді GloVe векторларын қолдана отырып, екі сөздің қаншалықты ұқсас екенін анықтай алатыныңызды көрейік."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArqmE8RUm0OH"
   },
   "source": [
    "# 1 - Косинустық ұқсастық\n",
    "\n",
    "Екі сөздің қаншалықты ұқсас екенін өлшеу үшін, олардың эмбеддинг векторлары арасындағы ұқсастық дәрежесін анықтайтын әдіс қажет. Екі вектор \\(u\\) және \\(v\\) берілген жағдайда, косинустық ұқсастық келесі түрде анықталады:\n",
    "\n",
    "$$\\text{CosineSimilarity(u, v)} = \\frac {u \\cdot v} {||u||_2 \\, ||v||_2} = \\cos(\\theta) \\tag{1}$$\n",
    "\n",
    "мұнда $(u \\cdot v)$ — екі вектордың скалярлық көбейтіндісі (немесе ішкі көбейтіндісі), $(||u||_2)$ — $(u)$ векторының нормасы (немесе ұзындығы), және $(\\theta)$ — $(u)$ мен $(v$) арасындағы бұрыш. Бұл ұқсастық $(u$) мен $(v)$ арасындағы бұрышқа байланысты. Егер $(u)$ және $(v$) өте ұқсас болса, олардың косинустық ұқсастығы 1-ге жақын болады; егер олар ұқсастық көрсетпесе, онда косинустық ұқсастықтың мәні кіші болады.\n",
    "\n",
    "<img src=\"images/cosine_sim.png\" style=\"width:800px;height:250px;\">\n",
    "<caption><center> **Сурет 1**: Екі вектор арасындағы бұрыштың косинусы олардың ұқсастығын өлшейді</center></caption>\n",
    "\n",
    "**Тапсырма**: `cosine_similarity()` функциясын жүзеге асырып, сөз векторлары арасындағы ұқсастықты бағалаңыз.\n",
    "\n",
    "**Ескерту**: \\(u\\) векторының нормасы былай анықталады:\n",
    "$$ ||u||_2 = \\sqrt{\\sum_{i=1}^{n} u_i^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWQ_l6gJUeS6"
   },
   "source": [
    "# Тапсырма 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Id4MFbCmm0OI",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(u, v):\n",
    "    \"\"\"\n",
    "    Косинустық ұқсастық u және v арасындағы ұқсастық дәрежесін көрсетеді\n",
    "\n",
    "    Түсіктемелер:\n",
    "        u -- (n,) өлшемді сөз векторы\n",
    "        v -- (n,) өлшемді сөз векторы\n",
    "\n",
    "    Қайтарады:\n",
    "        cosine_similarity -- жоғарыда берілген формула бойынша анықталған u және v арасындағы косинустық ұқсастық.\n",
    "    \"\"\"\n",
    "\n",
    "    distance = 0.0\n",
    "\n",
    "    ### МҰНДА КОДЫҢЫЗДЫ ЖАЗЫҢЫЗ ###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### КОД МҰНДА АЯҚТАЛАДЫ ###\n",
    "\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbysGlAlm0OI",
    "outputId": "b3c08c33-405e-4ea8-ad5c-8e807b607c3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarity(father, mother) =  0.8909038442893615\n",
      "cosine_similarity(france - paris, rome - italy) =  -0.6751479308174202\n"
     ]
    }
   ],
   "source": [
    "father = word_to_vec_map[\"father\"]\n",
    "mother = word_to_vec_map[\"mother\"]\n",
    "ball = word_to_vec_map[\"ball\"]\n",
    "france = word_to_vec_map[\"france\"]\n",
    "italy = word_to_vec_map[\"italy\"]\n",
    "paris = word_to_vec_map[\"paris\"]\n",
    "rome = word_to_vec_map[\"rome\"]\n",
    "\n",
    "print(\"cosine_similarity(father, mother) = \", cosine_similarity(father, mother))\n",
    "print(\"cosine_similarity(france - paris, rome - italy) = \",cosine_similarity(france - paris, rome - italy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8HyQChlm0OI"
   },
   "source": [
    "**Күтілетін нәтиже**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **cosine_similarity(father, mother)** =\n",
    "        </td>\n",
    "        <td>\n",
    "         0.890903844289\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **cosine_similarity(france - paris, rome - italy)** =\n",
    "        </td>\n",
    "        <td>\n",
    "         -0.675147930817\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNdVtoijm0OJ"
   },
   "source": [
    "Дұрыс күтілетін нәтижені алғаннан кейін, кірістерді өзгертіп, басқа сөздер жұптары арасындағы косинус ұқсастығын өлшеңіз! Басқа кірістердің косинус ұқсастығына қатысты ойнау сізге сөз векторларының қалай әрекет ететінін жақсырақ түсінуге мүмкіндік береді."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdL9GlSHm0OJ"
   },
   "source": [
    "## 2 - Сөз аналогиясы тапсырмасы\n",
    "\n",
    "Сөз аналогиясы тапсырмасында біз \"<font color='brown'>*a* сөзі *b* сөзіне ұқсас, *c* сөзіне **____**</font>\" сөйлемін толықтырамыз. Мысалы, <font color='brown'>'*man* сөзі *woman* сөзіне ұқсас, *king* сөзі *queen* сөзіне'</font> деген аналогия. Нақтырақ айтқанда, біз *d* сөзін табуға тырысамыз, мұнда сәйкес сөз векторлары $(e_a, e_b, e_c, e_d)$ келесі түрде байланысты:\n",
    "\n",
    "\n",
    "$e_b - e_a \\approx e_d - e_c$\n",
    "\n",
    "$e_b - e_a$ және $e_d - e_c$ арасындағы ұқсастықты косинустық ұқсастық арқылы өлшейміз.\n",
    "\n",
    "**Тапсырма**: Төмендегі кодты толықтырып, сөз аналогияларын орындауға мүмкіндік беріңіз!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eES5kq9cUknU"
   },
   "source": [
    "# Тапсырма 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "g1eQlik8m0OJ",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(u, v):\n",
    "    \"\"\"\n",
    "    Екі вектор арасындағы косинустық ұқсастықты есептейді.\n",
    "    \"\"\"\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
    "\n",
    "def complete_analogy(word_a, word_b, word_c, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Сөз аналогиясы тапсырмасын орындайды: word_a сөзі word_b сөзіне ұқсас, word_c сөзіне ____.\n",
    "\n",
    "    Түсіктемелер:\n",
    "    word_a -- бір сөз, жол (string).\n",
    "    word_b -- бір сөз, жол (string).\n",
    "    word_c -- бір сөз, жол (string).\n",
    "    word_to_vec_map -- сөздерді олардың сәйкес векторларына сәйкестендіретін сөздік.\n",
    "\n",
    "    Қайтарады:\n",
    "    best_word -- (v_b - v_a) мен (v_best - v_c) арасындағы косинустық ұқсастық арқылы өлшенген ұқсастығы бар сөз.\n",
    "    \"\"\"\n",
    "    # Сөздерді кіші әріпке ауыстыру\n",
    "    word_a, word_b, word_c =\n",
    "\n",
    "    # word embedding алу\n",
    "    e_a =\n",
    "    e_b =\n",
    "    e_c =\n",
    "\n",
    "    # Барлық сөздердің табылғанын тексеру\n",
    "    if e_a is None or e_b is None or e_c is None:\n",
    "        missing = [w for w, e in zip([word_a, word_b, word_c], [e_a, e_b, e_c]) if e is None]\n",
    "        raise ValueError(\"Келесі сөз(дер) эмбеддинг сөздігінде жоқ: \" + \", \".join(missing))\n",
    "\n",
    "    # Барлық енгізулердің өлшемдері бірдей екендігін тексеру\n",
    "    if e_a.shape != e_b.shape or e_a.shape != e_c.shape:\n",
    "        raise ValueError(\"Эмбеддингтердің өлшемдері сәйкес келмейді!\")\n",
    "\n",
    "    words = word_to_vec_map.keys()\n",
    "    max_cosine_sim = -100  # өте кіші мәнмен инициализациялау\n",
    "    best_word = None\n",
    "\n",
    "    # Нысаналы векторды есептеу: word_b және word_a арасындағы айырмашылық\n",
    "    target_vec =\n",
    "\n",
    "    # Сөздік бойынша барлық сөздерді шоламыз\n",
    "    for w in words:\n",
    "        # Кіріс сөздерді өткізіп жіберу\n",
    "        if w in [word_a, word_b, word_c]:\n",
    "            continue\n",
    "\n",
    "        # Ағымдағы сөздің енгізуін алып, өлшемін тексеру\n",
    "        e_w = word_to_vec_map.get(w)\n",
    "        if e_w is None or e_w.shape != e_c.shape:\n",
    "            continue  # Өлшемдері сәйкес келмейтін сөздерді өткізіп жіберу\n",
    "\n",
    "        # (Нысаналы вектор) мен (e_w - e_c) арасындағы косинустық ұқсастықты есептеу\n",
    "        cosine_sim =\n",
    "\n",
    "        # Жаңа максималды ұқсастық табылса, best_word жаңарту\n",
    "        if cosine_sim > max_cosine_sim:\n",
    "            max_cosine_sim = cosine_sim\n",
    "            best_word = w\n",
    "\n",
    "    return best_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAnE-Um1m0OJ"
   },
   "source": [
    "Run the cell below to test your code, this may take 1-2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XVaAj3h9m0OJ",
    "outputId": "da2f71d8-41e2-4b7e-800b-a787b630470e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "italy -> italian :: kazakhstan -> kazakh\n",
      "india -> delhi :: japan -> tokyo\n",
      "man -> woman :: boy -> girl\n",
      "small -> smaller :: large -> larger\n"
     ]
    }
   ],
   "source": [
    "triads_to_try = [('italy', 'italian', 'kazakhstan'), ('india', 'delhi', 'japan'), ('man', 'woman', 'boy'), ('small', 'smaller', 'large')]\n",
    "for triad in triads_to_try:\n",
    "    print('{} -> {} :: {} -> {}'.format( *triad, complete_analogy(*triad,word_to_vec_map)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRU2spdem0OJ"
   },
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **italy -> italian** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         kazakhstan -> kazakh\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **india -> delhi** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         japan -> tokyo\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **man -> woman ** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         boy -> girl\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **small -> smaller ** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         large -> larger\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJCJWh1Om0OK"
   },
   "source": [
    "Дұрыс күтілетін нәтижені алғаннан кейін, өзіңіздің ұқсастықтарыңызды тексеру үшін жоғарыдағы енгізу ұяшықтарын өзгертіңіз. Жұмыс істейтін басқа аналогиялық жұптарды табуға тырысыңыз, сонымен қатар алгоритм дұрыс жауап бермейтін кейбір жұптарды табыңыз: Мысалы, сіз small->small as big->? әрекетін жасай аласыз."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzPwOktrm0OK"
   },
   "source": [
    "## 3 - Сөз векторларын бейссіздендіру"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctDydAhOm0OK"
   },
   "source": [
    "Келесі тапсырмада сіз сөз енгізулерінде бейнеленуі мүмкін жыныстық бейсімділікті қарастырып, оны азайту алгоритмдерін зерттейсіз. Бейссіздендіру тақырыбын үйренуден басқа, бұл тапсырма сөз векторларының не істеп жатқанын түсіну интуицияңызды да жетілдіруге көмектеседі. Бұл бөлімде сәл сызықтық алгебра қатысады, дегенмен сызықтық алгебрада сарапшы болмаған жағдайда да тапсырманы орындап көруге болады, сондықтан оны сынап көріңіз.\n",
    "\n",
    "Алдымен GloVe сөз енгізулерінің жыныспен қалай байланысатынын қарастырайық. Сіз алдымен $g = e_{woman} - e_{man}$ векторын есептейсіз, мұнда $e_{woman}$ *woman* сөзіне сәйкес сөз векторын, ал $e_{man}\\$ *man* сөзіне сәйкес сөз векторын білдіреді. Алынған g векторы шамамен \"жыныс\" ұғымын кодтайды.\n",
    "\n",
    "Егер сіз $g_1 = e_{mother} - e_{father}$, $g_2 = e_{girl} - e_{boy}$ т.б. есептеп, олардың орташа мәнін алсаңыз, дәлдік жоғарырақ болуы мүмкін. Бірақ қазір үшін тек $e_{woman} - e_{man}$ қолдану жеткілікті нәтижелер береді.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JlcPH4Flm0OK",
    "outputId": "3dd7366b-7437-469a-ac45-390c38cebdb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.087144    0.2182     -0.40986    -0.03922    -0.1032      0.94165\n",
      " -0.06042     0.32988     0.46144    -0.35962     0.31102    -0.86824\n",
      "  0.96006     0.01073     0.24337     0.08193    -1.02722    -0.21122\n",
      "  0.695044   -0.00222     0.29106     0.5053     -0.099454    0.40445\n",
      "  0.30181     0.1355     -0.0606     -0.07131    -0.19245    -0.06115\n",
      " -0.3204      0.07165    -0.13337    -0.25068714 -0.14293    -0.224957\n",
      " -0.149       0.048882    0.12191    -0.27362    -0.165476   -0.20426\n",
      "  0.54376    -0.271425   -0.10245    -0.32108     0.2516     -0.33455\n",
      " -0.04371     0.01258   ]\n"
     ]
    }
   ],
   "source": [
    "g = word_to_vec_map['woman'] - word_to_vec_map['man']\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWhBMxUJm0OK"
   },
   "source": [
    "Енді сіз $g$-мен әртүрлі сөздердің косинус ұқсастығын қарастырасыз. Ұқсастықтың оң мәні теріс косинус ұқсастығымен нені білдіретінін қарастырыңыз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WTuEr9R5m0OL",
    "outputId": "408ff887-40b8-4f95-d16e-0068896aba8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Атаулар тізімі және олардың құрастырылған вектормен ұқсастықтары:\n",
      "john -0.23163356145973724\n",
      "paul -0.24886984523936856\n",
      "alex -0.1289169612113885\n",
      "peter -0.23759410929536404\n",
      "susan 0.23975381925741865\n"
     ]
    }
   ],
   "source": [
    "print ('Атаулар тізімі және олардың құрастырылған вектормен ұқсастықтары:')\n",
    "\n",
    "# қыздар мен ұлдардың аты\n",
    "name_list = ['john','paul','alex','peter','susan']\n",
    "\n",
    "for w in name_list:\n",
    "    print (w, cosine_similarity(word_to_vec_map[w], g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgYRbEjTm0OL"
   },
   "source": [
    "Көріп отырғаныңыздай, әйел есімдері біздің құрастырылған $g$ векторымен оң косинус ұқсастығына ие, ал ер есімдері теріс косинус ұқсастығына ие. Бұл таңқаларлық емес және нәтиже қолайлы болып көрінеді.\n",
    "\n",
    "Бірақ басқа сөздерді қолданып көрейік."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1eEhiUGIm0OL",
    "outputId": "329dab04-dcaf-44f9-cf4f-c67e2d8e17b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Басқа сөздер және олардың ұқсастықтары:\n",
      "man -0.11711095765336832\n",
      "woman 0.35666618846270376\n",
      "guns -0.1888485567898898\n",
      "science -0.06082906540929701\n",
      "arts 0.008189312385880337\n",
      "literature 0.06472504433459932\n",
      "doctor 0.11895289410935041\n",
      "tree -0.07089399175478091\n",
      "technology -0.13193732447554302\n",
      "fashion 0.03563894625772699\n",
      "teacher 0.17920923431825664\n",
      "engineer -0.0803928049452407\n",
      "pilot 0.0010764498991916937\n",
      "computer -0.10330358873850498\n",
      "singer 0.1850051813649629\n"
     ]
    }
   ],
   "source": [
    "print('Басқа сөздер және олардың ұқсастықтары:')\n",
    "word_list = ['man','woman',\n",
    "             'guns', 'science', 'arts', 'literature','doctor', 'tree',\n",
    "             'technology',  'fashion', 'teacher', 'engineer', 'pilot', 'computer', 'singer']\n",
    "for w in word_list:\n",
    "    print (w, cosine_similarity(word_to_vec_map[w], g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11NZjZDxm0OL"
   },
   "source": [
    "Сіз таңқаларлық нәрсені байқадыңыз ба? Бұл нәтижелердің белгілі бір зиянды гендерлік стереотиптерді қалай көрсететіні таң қалдырады. Мысалы, «компьютер» «ер адамға» жақын болса, «әдебиет» «әйелге» жақын.\n",
    "\n",
    "Төменде [Boliukbasi et al., 2016](https://arxiv.org/abs/1607.06520) негізіндегі алгоритмді пайдаланып, осы векторлардың қиғаштығын қалай азайтуға болатынын көреміз. \"Актер\"/\"актриса\" немесе \"әже\"/\"ата\" сияқты кейбір сөз жұптары гендерлік ерекшелігі болып қалуы керек, ал \"ресепшн\" немесе \"технология\" сияқты басқа сөздер бейтараптандырылуы керек, яғни жынысқа қатысты болмауы керек. Сіз бұл екі түрдегі сөздерді айыру кезінде басқаша қарауыңыз керек.\n",
    "\n",
    "### 3.1 - Гендерлік емес сөздерге қарсылықты бейтараптандыру\n",
    "\n",
    "Төмендегі сурет бейтараптандырудың не істейтінін көруге көмектеседі. 50 өлшемді сөзді ендіруді пайдалансаңыз, 50 өлшемді кеңістікті екі бөлікке бөлуге болады: $g$ қиғаштық бағыты және біз $g_{\\perp}$ деп атайтын қалған 49 өлшем. Сызықтық алгебрада 49 өлшемді $g_{\\perp}$ $g$-ға перпендикуляр (немесе «отогональ») деп айтамыз, яғни ол $g$-ға 90 градуста. Бейтараптандыру қадамы $e_{receptionist}$ сияқты векторды қабылдайды және компонентті $g$ бағытында нөлге түсіріп, бізге $e_{receptionist}^{debiased}$ береді.\n",
    "\n",
    "$g_{\\perp}$ 49 өлшемді болса да, экранда сурет салуға болатын шектеулерді ескере отырып, біз оны төмендегі 1 өлшемді ось арқылы суреттейміз.\n",
    "\n",
    "<img src=\"images/neutral.png\" style=\"width:800px;height:300px;\">\n",
    "<caption><center> **2-сурет**: Бейтараптандыру операциясын қолданғанға дейін және одан кейін берілген \"ресепшн\" сөзі векторы. </center></caption>\n",
    "\n",
    "**Жаттығу**: «Қабылдау қызметкері» немесе «ғалым» сияқты сөздердің қисындылығын жою үшін «бейтараптандыру()» әрекетін орындаңыз. $e$ ендірілген енгізуді ескере отырып, $e^{debiased}$ есептеу үшін келесі формулаларды пайдалануға болады:\n",
    "\n",
    "$$e^{bias\\_component} = \\frac{e \\cdot g}{||g||_2^2} * g\\tag{2}$$\n",
    "$$e^{debiased} = e - e^{bias\\_component}\\tag{3}$$\n",
    "\n",
    "Егер сіз сызықтық алгебраның маманы болсаңыз, $e^{bias\\_component}$ $e$-дың $g$ бағытына проекциясы ретінде тануға болады. Егер сіз сызықтық алгебраның маманы болмасаңыз, бұл туралы алаңдамаңыз.\n",
    "\n",
    "<!--\n",
    "**Еске салғыш**: $u$ векторын екі бөлікке бөлуге болады: оның $v_B$ вектор осіне проекциясы және $v$-ға ортогональ осіне проекциясы:\n",
    "$$u = u_B + u_{\\perp}$$\n",
    "мұндағы: $u_B = $ және $ u_{\\perp} = u - u_B $\n",
    "!-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujYwKBGFUoYf"
   },
   "source": [
    "# Тапсырма 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Z_t_GShTm0OL",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def neutralize(word, g, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    \"word\" сөзінің бейсін жою үшін, оны бейс осіне (мысалы, жыныс) тік бұрышты кеңістікке проекциялайды.\n",
    "    Бұл функция жыныстық бейссіз сөздердің жыныс субкеңістігінде нөлге тең болуын қамтамасыз етеді.\n",
    "\n",
    "    Түсіктемелер:\n",
    "        word -- бейссіздендіру қажет сөзді көрсететін жол (string)\n",
    "        g -- бейс осіне сәйкес (мысалы, жыныс) (50,) өлшемді numpy-массиві\n",
    "        word_to_vec_map -- сөздерді олардың сәйкес векторларымен сәйкестендіретін сөздік\n",
    "\n",
    "    Қайтарады:\n",
    "        e_debiased -- енгізілген \"word\" сөзінің бейссіздендірілген векторлық бейнеленуі\n",
    "    \"\"\"\n",
    "\n",
    "    ### МҰНДА КОДЫҢЫЗДЫ ЖАЗЫҢЫЗ ###\n",
    "    # \"word\" сөзінің векторлық бейнесін таңдаңыз. word_to_vec_map қолданыңыз. (шамамен 1 жол)\n",
    "    e =\n",
    "\n",
    "    # Жоғарыда берілген формула бойынша e_biascomponent-ті есептеңіз. (шамамен 1 жол)\n",
    "    e_biascomponent =\n",
    "\n",
    "    # e-ден e_biascomponent-ті алып тастау арқылы бейссіздендіріңіз\n",
    "    # e_debiased оның тік проекциясына тең болуы тиіс. (шамамен 1 жол)\n",
    "    e_debiased =\n",
    "    ### МҰНДА КОД АЯҚТАЛАДЫ ###\n",
    "\n",
    "    return e_debiased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mwqcPtiJm0OM",
    "outputId": "f949b02a-5913-4084-e7d7-e43730122b6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Бейссіздендірмес бұрын guns және g арасындағы косинустық ұқсастық:  -0.1888485567898898\n",
      "Бейссіздендіргеннен кейін guns және g арасындағы косинустық ұқсастық:  1.1767167173222674e-17\n"
     ]
    }
   ],
   "source": [
    "e = \"guns\"\n",
    "print(\"Бейссіздендірмес бұрын \" + e + \" және g арасындағы косинустық ұқсастық: \", cosine_similarity(word_to_vec_map[\"guns\"], g))\n",
    "\n",
    "e_debiased = neutralize(\"guns\", g, word_to_vec_map)\n",
    "print(\"Бейссіздендіргеннен кейін \" + e + \" және g арасындағы косинустық ұқсастық: \", cosine_similarity(e_debiased, g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97KdOPZWm0OM"
   },
   "source": [
    "### 3.2 - Гендерлік сөздерді теңестіру алгоритмі\n",
    "\n",
    "Әрі қарай, «актриса» және «актер» сияқты сөз жұптарына дефазаны қалай қолдануға болатынын көрейік. Теңестіру тек жыныс сипаты арқылы ерекшеленгіңіз келетін сөздер жұптарына қолданылады. Нақты мысал ретінде, «актриса» «актер» дегеннен гөрі «бала күтіміне» жақын делік. «Бала күтіміне» бейтараптандыруды қолдану арқылы біз бала күтумен байланысты гендерлік стереотипті азайта аламыз. Бірақ бұл әлі де «актер» мен «актрисаның» «бала күтуінен» бірдей қашықтықта екеніне кепілдік бермейді. Бұл туралы теңестіру алгоритмі айналысады.\n",
    "\n",
    "Теңестірудің негізгі идеясы - белгілі бір сөздер жұбының 49 өлшемді $g_\\perp$-дан бірдей қашықтықта екеніне көз жеткізу. Теңестіру қадамы сонымен қатар екі теңестірілген қадамның $e_{receptionist}^{debiased}$ немесе бейтараптандырылған кез келген басқа жұмыстардан бірдей қашықтықта болуын қамтамасыз етеді. Суреттерде теңестіру осылай жұмыс істейді:\n",
    "\n",
    "<img src=\"images/equalize10.png\" style=\"width:800px;height:400px;\">\n",
    "\n",
    "\n",
    "Мұны істеу үшін сызықтық алгебраны шығару біршама күрделірек. (Толық ақпарат алу үшін Bolukbasi et al., 2016 қараңыз.) Бірақ негізгі теңдеулер:\n",
    "\n",
    "$$ \\mu = \\frac{e_{w1} + e_{w2}}{2}\\tag{4}$$\n",
    "\n",
    "$$ \\mu_{B} = \\frac {\\mu \\cdot \\text{bias_axis}}{||\\text{bias_axis}||_2^2} *\\text{bias_axis}\n",
    "\\tag{5}$$\n",
    "\n",
    "$$\\mu_{\\perp} = \\mu - \\mu_{B} \\tag{6}$$\n",
    "\n",
    "$$ e_{w1B} = \\frac {e_{w1} \\cdot \\text{bias_axis}}{||\\text{bias_axis}||_2^2} *\\text{bias_axis}\n",
    "\\tag{7}$$\n",
    "$$ e_{w2B} = \\frac {e_{w2} \\cdot \\text{bias_axis}}{||\\text{bias_axis}||_2^2} *\\text{bias_axis}\n",
    "\\tag{8}$$\n",
    "\n",
    "\n",
    "$$e_{w1B}^{түзетілді} = \\sqrt{ |{1 - ||\\mu_{\\perp} ||^2_2} |} * \\frac{e_{\\text{w1B}} - \\mu_B} {|(e_{w1} - \\mu_{\\perp}) - \\mu_B)|} \\$$g{} \\ta\n",
    "\n",
    "\n",
    "$$e_{w2B}^{түзетілген} = \\sqrt{ |{1 - ||\\mu_{\\perp} ||^2_2} |} * \\frac{e_{\\text{w2B}} - \\mu_B} {|(e_{w2} - \\mu_{\\perp}) - \\mu_B)|} \\$g\n",
    "\n",
    "$$e_1 = e_{w1B}^{түзетілді} + \\mu_{\\perp} \\tag{11}$$\n",
    "$$e_2 = e_{w2B}^{түзетілген} + \\mu_{\\perp} \\tag{12}$$\n",
    "\n",
    "\n",
    "**Жаттығу**: Төмендегі функцияны орындаңыз. Сөздердің соңғы теңестірілген нұсқасын алу үшін жоғарыдағы теңдеулерді пайдаланыңыз. Іске сәт!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "N-4CAqT9m0OM",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def equalize(pair, bias_axis, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Жоғарыдағы суретте сипатталған теңестіргіш әдіс арқылы жынысқа тән сөздердің бейсін жояды.\n",
    "\n",
    "    Түсіктемелер:\n",
    "    pair -- жынысқа тән сөздердің жұбы (мысалы, (\"actress\", \"actor\"))\n",
    "    bias_axis -- бейс осіне сәйкес (мысалы, жыныс) (50,) өлшемді numpy-массиві\n",
    "    word_to_vec_map -- сөздерді олардың сәйкес векторларымен сәйкестендіретін сөздік\n",
    "\n",
    "    Қайтарады:\n",
    "    e_1 -- бірінші сөзге сәйкес вектор\n",
    "    e_2 -- екінші сөзге сәйкес вектор\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # 1-қадам: \"word\" сөзінің векторлық бейнесін таңдаңыз. word_to_vec_map қолданыңыз. (шамамен 2 жол)\n",
    "    w1, w2 = pair[0], pair[1]\n",
    "    e_w1, e_w2 = word_to_vec_map[w1], word_to_vec_map[w2]\n",
    "\n",
    "    # 2-қадам: e_w1 және e_w2-ның орташа мәнін есептеңіз (шамамен 1 жол)\n",
    "    mu = (e_w1 + e_w2) / 2\n",
    "\n",
    "    # 3-қадам: mu-ның бейс осіне және оған тік ось бойынша проекциясын есептеңіз (шамамен 2 жол)\n",
    "    mu_B = (np.dot(mu, bias_axis) / np.linalg.norm(bias_axis)**2) * bias_axis\n",
    "    mu_orth = mu - mu_B\n",
    "\n",
    "    # 4-қадам: Формулалар (7) және (8) арқылы e_w1B және e_w2B мәндерін есептеңіз (шамамен 2 жол)\n",
    "    e_w1B = (np.dot(e_w1, bias_axis) / np.linalg.norm(bias_axis)**2) * bias_axis\n",
    "    e_w2B = (np.dot(e_w2, bias_axis) / np.linalg.norm(bias_axis)**2) * bias_axis\n",
    "\n",
    "    # 5-қадам: Жоғарыда берілген (9) және (10) формулаларын қолданып, e_w1B және e_w2B мәндерін түзетіңіз (шамамен 2 жол)\n",
    "    corrected_e_w1B = np.sqrt(np.abs(1 - np.linalg.norm(mu_orth)**2)) * ((e_w1B - mu_B) / np.abs((e_w1 - mu_orth) - mu_B))\n",
    "    corrected_e_w2B = np.sqrt(np.abs(1 - np.linalg.norm(mu_orth)**2)) * ((e_w2B - mu_B) / np.abs((e_w2 - mu_orth) - mu_B))\n",
    "\n",
    "    # 6-қадам: Түзетілген проекциялардың қосындысына теңестіріп, e1 және e2 сөз векторларын бейссіздендіріңіз (шамамен 2 жол)\n",
    "    e1 = corrected_e_w1B + mu_orth\n",
    "    e2 = corrected_e_w2B + mu_orth\n",
    "\n",
    "    return e1, e2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tIkuyTTGm0OM",
    "outputId": "08a66a32-5d93-4a38-e448-77b109bc6e64",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Теңестірмес бұрынғы косинустық ұқсастықтар:\n",
      "cosine_similarity(word_to_vec_map[\"man\"], gender) =  -0.11711095765336832\n",
      "cosine_similarity(word_to_vec_map[\"woman\"], gender) =  0.35666618846270376\n",
      "\n",
      "Теңестіргеннен кейінгі косинустық ұқсастықтар:\n",
      "cosine_similarity(e1, gender) =  -0.7165727525843935\n",
      "cosine_similarity(e2, gender) =  0.7396596474928909\n"
     ]
    }
   ],
   "source": [
    "print(\"Теңестірмес бұрынғы косинустық ұқсастықтар:\")\n",
    "print(\"cosine_similarity(word_to_vec_map[\\\"man\\\"], gender) = \", cosine_similarity(word_to_vec_map[\"man\"], g))\n",
    "print(\"cosine_similarity(word_to_vec_map[\\\"woman\\\"], gender) = \", cosine_similarity(word_to_vec_map[\"woman\"], g))\n",
    "print()\n",
    "e1, e2 = equalize((\"man\", \"woman\"), g, word_to_vec_map)\n",
    "print(\"Теңестіргеннен кейінгі косинустық ұқсастықтар:\")\n",
    "print(\"cosine_similarity(e1, gender) = \", cosine_similarity(e1, g))\n",
    "print(\"cosine_similarity(e2, gender) = \", cosine_similarity(e2, g))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "id3YHO__m0ON",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Жоғарыдағы ұяшықтағы кіріс сөздермен ойнап, басқа сөздер жұптарына теңестіруді қолданыңыз.\n",
    "\n",
    "Бұл бұрмалау алгоритмдері ауытқуды азайту үшін өте пайдалы, бірақ мінсіз емес және барлық ауытқу іздерін жоймайды. Мысалы, бұл іске асырудың бір осал тұсы $g$ қиғаштық бағыты тек _әйел_ және _ер_ сөздерінің жұбын қолдану арқылы анықталған. Бұрын талқыланғандай, егер $g$ есептеу арқылы анықталған болса $g_1 = e_{әйел} - e_{er}$; $g_2 = e_{ана} - e_{әке}$; $g_3 = e_{қыз} - e_{boy}$; және т.б. және олардың үстінен орташа алғанда, 50 өлшемді сөзді ендіру кеңістігіндегі \"гендерлік\" өлшемді жақсырақ бағалауды аласыз. Мұндай нұсқалармен де ойнауға болады."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSI2dzYnm0OO"
   },
   "source": [
    "**Анықтамалар**:\n",
    "- The debiasing algorithm is from Bolukbasi et al., 2016, [Man is to Computer Programmer as Woman is to\n",
    "Homemaker? Debiasing Word Embeddings](https://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings.pdf)\n",
    "- The GloVe word embeddings were due to Jeffrey Pennington, Richard Socher, and Christopher D. Manning. (https://nlp.stanford.edu/projects/glove/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbl-yiv0m0OK"
   },
   "source": [
    "### Құттықтаймыз!\n",
    "\n",
    "Сіз осы тапсырманың соңына жеттіңіз. Есіңізде сақтау керек негізгі нүктелер:\n",
    "\n",
    "- Косинустық ұқсастық — сөз векторлары жұбының ұқсастығын салыстырудың жақсы әдісі. (Алайда, L2 қашықтық та жұмыс істейді.)\n",
    "- Тілдік қосымшаларда интернеттен алдын ала үйретілген сөз векторларын пайдалану жиі жақсы бастама болып табылады.\n",
    "\n",
    "Бағаланған бөлімдерді аяқтағаныңызға қарамастан, осы дәптердегі қалған бөлімдерді де қарауды ұсынамыз.\n",
    "\n",
    "Осы дәптердің бағаланған бөлімдерін аяқтағаныңызбен құттықтаймыз!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "8hb5s",
   "launcher_item_id": "5NrJ6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
